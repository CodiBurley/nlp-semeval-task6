{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>Blessed are the peacemakers, for they shall be...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>I am not conformed to this world. I am transfo...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>Salah should be prayed with #focus and #unders...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>And stay in your houses and do not display you...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>Blessed are the peacemakers, for they shall be...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>I am not conformed to this world. I am transfo...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>Salah should be prayed with #focus and #unders...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>And stay in your houses and do not display you...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('trainingData.txt', sep='\\t', encoding='latin1', index_col='ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then extract the topics (for now just focus on hillary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Atheism',\n",
       " 'Climate Change is a Real Concern',\n",
       " 'Feminist Movement',\n",
       " 'Hillary Clinton',\n",
       " 'Legalization of Abortion']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTopics = []\n",
    "for row in df['Target']:\n",
    "    if row not in listOfTopics:\n",
    "        listOfTopics.append(row)\n",
    "listOfTopics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to turn the stance into usable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yVec(text):\n",
    "    if text == 'AGAINST':\n",
    "        return -1\n",
    "    elif text == 'FAVOR':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract topic rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>513</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>Just listened to the most inspirational speech...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>513</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Atheism</td>\n",
       "      <td>Just listened to the most inspirational speech...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atheismDF = df.loc[df['Target'] == 'Atheism']\n",
    "atheismDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make corpus from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "Y = []\n",
    "for index, row in atheismDF.iterrows():\n",
    "    corpus.append(row['Tweet'][:-6])\n",
    "    Y.append(yVec(row['Stance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make custom tokenizer to remove some common elements in tweets that we don't want marked as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customTokenize(tweet):\n",
    "    tokenList = TweetTokenizer().tokenize(tweet)\n",
    "    print(tokenList)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate ngrams of size 2-4.  Drop anything with less then 3 occurences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '! !',\n",
       " '! ! !',\n",
       " '! #lovewins',\n",
       " '\"',\n",
       " '#bha2015',\n",
       " '#bible',\n",
       " '#catholic',\n",
       " '#christ',\n",
       " '#christianity',\n",
       " '#church',\n",
       " '#freedom',\n",
       " '#freethinker',\n",
       " '#god',\n",
       " '#god ,',\n",
       " '#hope',\n",
       " '#identity',\n",
       " '#islam',\n",
       " '#life',\n",
       " '#love',\n",
       " '#lovewins',\n",
       " '#peace',\n",
       " '#quote',\n",
       " '#rosary',\n",
       " '#rosary #teamjesus',\n",
       " '#spirituality',\n",
       " '#tcot',\n",
       " '#teamjesus',\n",
       " '#truth',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ', \"',\n",
       " ', .',\n",
       " ', know',\n",
       " ', pray',\n",
       " ', pray sinners',\n",
       " ', pray sinners hour',\n",
       " '-',\n",
       " '- ps',\n",
       " '- ps .',\n",
       " '.',\n",
       " '. \"',\n",
       " '. #freethinker',\n",
       " '. #god',\n",
       " '. #islam',\n",
       " '. #love',\n",
       " '. #lovewins',\n",
       " '. #rosary',\n",
       " '. #rosary #teamjesus',\n",
       " '. #spirituality',\n",
       " '. (',\n",
       " '. -',\n",
       " '. amen',\n",
       " '. amen .',\n",
       " '. amen . #rosary',\n",
       " \". don't\",\n",
       " '. god',\n",
       " '. love',\n",
       " \". there's\",\n",
       " \". there's god\",\n",
       " '. ~',\n",
       " '..',\n",
       " '...',\n",
       " '/',\n",
       " '1',\n",
       " '2',\n",
       " ':',\n",
       " ': \"',\n",
       " ':)',\n",
       " ';',\n",
       " '?',\n",
       " '@prayerbullets',\n",
       " '@prayerbullets :',\n",
       " 'age',\n",
       " 'allow',\n",
       " 'amazing',\n",
       " 'amen',\n",
       " 'amen .',\n",
       " 'amen . #rosary',\n",
       " 'amen . #rosary #teamjesus',\n",
       " 'america',\n",
       " 'ask',\n",
       " 'atheism',\n",
       " 'atheist',\n",
       " 'beautiful',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believe god',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bible',\n",
       " 'bless',\n",
       " 'bless .',\n",
       " 'blessed',\n",
       " 'book',\n",
       " \"can't\",\n",
       " 'care',\n",
       " 'change',\n",
       " 'children',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christians',\n",
       " 'church',\n",
       " 'come',\n",
       " 'constitution',\n",
       " 'control',\n",
       " 'country',\n",
       " 'court',\n",
       " 'created',\n",
       " 'day',\n",
       " 'day ,',\n",
       " 'days',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'death .',\n",
       " 'death . amen',\n",
       " 'death . amen .',\n",
       " 'decision',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'earth',\n",
       " 'end',\n",
       " 'enemy',\n",
       " 'equality',\n",
       " 'evidence',\n",
       " 'face',\n",
       " 'faith',\n",
       " 'faith .',\n",
       " 'family',\n",
       " 'far',\n",
       " 'favor',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'forever',\n",
       " 'forward',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'gay',\n",
       " 'given',\n",
       " 'god',\n",
       " 'god ,',\n",
       " 'god , pray',\n",
       " 'god , pray sinners',\n",
       " 'god .',\n",
       " 'god ?',\n",
       " \"god's\",\n",
       " 'gods',\n",
       " 'going',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happy',\n",
       " 'having',\n",
       " \"he's\",\n",
       " 'heart',\n",
       " 'heaven',\n",
       " 'help',\n",
       " 'holy',\n",
       " 'holy mary',\n",
       " 'holy mary mother',\n",
       " 'holy mary mother god',\n",
       " 'hope',\n",
       " 'hour',\n",
       " 'hour death',\n",
       " 'hour death .',\n",
       " 'hour death . amen',\n",
       " 'human',\n",
       " 'humanist',\n",
       " \"i'm\",\n",
       " 'ignorance',\n",
       " 'impossible',\n",
       " \"it's\",\n",
       " 'jesus',\n",
       " 'jesus .',\n",
       " 'john',\n",
       " 'joy',\n",
       " 'judge',\n",
       " 'just',\n",
       " 'kingdom',\n",
       " 'know',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'leave',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'life',\n",
       " 'life ,',\n",
       " 'like',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'look',\n",
       " 'looks',\n",
       " 'lord',\n",
       " 'lord ,',\n",
       " 'lord .',\n",
       " 'love',\n",
       " 'love .',\n",
       " 'loves',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'marriage',\n",
       " 'mary',\n",
       " 'mary mother',\n",
       " 'mary mother god',\n",
       " 'mary mother god ,',\n",
       " 'matter',\n",
       " 'matthew',\n",
       " 'means',\n",
       " 'men',\n",
       " 'mercy',\n",
       " 'mind',\n",
       " 'mother',\n",
       " 'mother god',\n",
       " 'mother god ,',\n",
       " 'mother god , pray',\n",
       " 'need',\n",
       " 'o',\n",
       " 'old',\n",
       " 'peace',\n",
       " 'people',\n",
       " 'people ,',\n",
       " 'person',\n",
       " 'place',\n",
       " 'power',\n",
       " 'praise',\n",
       " 'pray',\n",
       " 'pray sinners',\n",
       " 'pray sinners hour',\n",
       " 'pray sinners hour death',\n",
       " 'prayer',\n",
       " 'prayers',\n",
       " 'prophet',\n",
       " 'proud',\n",
       " 'ps',\n",
       " 'ps .',\n",
       " 'psalm',\n",
       " 'purpose',\n",
       " 'question',\n",
       " 'quran',\n",
       " 'r',\n",
       " 'real',\n",
       " 'reality',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'religion',\n",
       " 'religion .',\n",
       " 'religions',\n",
       " 'religious',\n",
       " 'right',\n",
       " 'rt',\n",
       " 'rt @prayerbullets',\n",
       " 'rt @prayerbullets :',\n",
       " 's',\n",
       " 'say',\n",
       " 'seek',\n",
       " 'shall',\n",
       " 'sinners',\n",
       " 'sinners hour',\n",
       " 'sinners hour death',\n",
       " 'sinners hour death .',\n",
       " 'sins',\n",
       " 'spirit',\n",
       " 'stand',\n",
       " 'stop',\n",
       " 'tell',\n",
       " \"that's\",\n",
       " \"there's\",\n",
       " \"there's god\",\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thoughts',\n",
       " 'time',\n",
       " 'today',\n",
       " 'true',\n",
       " 'trust',\n",
       " 'trying',\n",
       " 'u',\n",
       " 'w',\n",
       " 'want',\n",
       " 'way',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'world .',\n",
       " 'years',\n",
       " \"you're\",\n",
       " '~']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 4), analyzer='word', stop_words='english', min_df=4, tokenizer=lambda x: TweetTokenizer().tokenize(x))\n",
    "\n",
    "X = ngram_vectorizer.fit_transform(corpus)\n",
    "\n",
    "ngram_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
