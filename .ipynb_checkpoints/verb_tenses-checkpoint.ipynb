{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from numpy import array as np_array\n",
    "\n",
    "TENSED_POS_TAGS = ['VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "STANCE_INDICES = {'FAVOR': 0, 'NONE': 1, 'AGAINST': 2}\n",
    "TAG_SET = {}\n",
    "\n",
    "\n",
    "def pos_tag(s):\n",
    "    return nltk.pos_tag(nltk.word_tokenize(s))\n",
    "\n",
    "\n",
    "def add_to_tag_set(s):\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(s['Tweet']))\n",
    "    for tag in tags:\n",
    "        if tag[1] in TAG_SET:\n",
    "            TAG_SET[tag[1]] = TAG_SET[tag[1]] + 1\n",
    "        else:\n",
    "            TAG_SET[tag[1]] = 1\n",
    "\n",
    "\n",
    "def get_tag_set(rows):\n",
    "    list(map(add_to_tag_set, rows))\n",
    "\n",
    "\n",
    "def tag_is_tensed(tag):\n",
    "    return tag[1] in TAG_SET\n",
    "\n",
    "\n",
    "def get_target_rows(d_frame, target):\n",
    "    if target == 'ALL':\n",
    "        return list(\n",
    "            map((lambda x: x[1]), d_frame.iterrows()))\n",
    "    return list(\n",
    "        filter((lambda row: row['Target'] == target),\n",
    "            map((lambda x: x[1]), d_frame.iterrows())))\n",
    "\n",
    "\n",
    "def get_tensed_tagged_words(rows):\n",
    "    return list(\n",
    "        map(\n",
    "            (lambda row:\n",
    "                list(filter(tag_is_tensed, pos_tag(row['Tweet'])))),\n",
    "            rows))\n",
    "\n",
    "\n",
    "def tensed_tag_counts(tags):\n",
    "    just_tags = list(map((lambda x: x[1]), tags))\n",
    "    return list(map((lambda tag: just_tags.count(tag)), TENSED_POS_TAGS))\n",
    "\n",
    "\n",
    "def get_x_train(tags_for_tweets):\n",
    "    return list(map(tensed_tag_counts, tags_for_tweets))\n",
    "\n",
    "\n",
    "def onehot_for_stance(stance):\n",
    "    one_hot = [0,0,0]\n",
    "    one_hot[STANCE_INDICES[stance]] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def get_y_train(rows):\n",
    "    return list(\n",
    "        map(onehot_for_stance,\n",
    "            map((lambda row: row['Stance']), rows)))\n",
    "\n",
    "\n",
    "def get_xy_data(filename, target):\n",
    "    training_df = pandas.read_csv(filename, sep='\\t', encoding='latin1')\n",
    "    target_rows = get_target_rows(training_df, target)\n",
    "    # Get tags\n",
    "    get_tag_set(target_rows)\n",
    "    tensed_tagged_tweets = get_tensed_tagged_words(target_rows)\n",
    "    x_train = get_x_train(tensed_tagged_tweets)\n",
    "    y_train = get_y_train(target_rows)\n",
    "    return (x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WRB': 388, 'DT': 3371, 'FW': 17, 'VBD': 681, ')': 97, 'RP': 175, 'RBS': 37, '#': 6540, 'NNS': 2445, 'IN': 4387, 'NNPS': 91, 'CC': 1184, 'LS': 2, 'UH': 36, 'MD': 790, 'VB': 2546, 'TO': 1229, '.': 3495, 'JJ': 4296, 'CD': 605, 'WDT': 115, '$': 36, ':': 664, '(': 75, '``': 237, 'WP$': 5, 'NN': 7469, 'PDT': 35, 'VBP': 2018, 'JJR': 136, 'VBN': 698, 'NNP': 10429, 'POS': 265, \"''\": 254, 'JJS': 118, 'RBR': 63, 'SYM': 4, 'VBG': 1073, 'WP': 336, 'VBZ': 1790, ',': 1179, 'RB': 2643, 'PRP$': 843, 'PRP': 2989, 'EX': 79}\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    'ALL': 'ALL',\n",
    "    'HILLARY': 'Hillary Clinton',\n",
    "    'ABORTION': 'Legalization of Abortion'\n",
    "}\n",
    "\n",
    "(x_train, y_train) = get_xy_data('trainingdata.txt', labels['ALL'])\n",
    "(x_test, y_test) = get_xy_data('trialdata.txt', labels['ALL'])\n",
    "\n",
    "# LEARN\n",
    "model = Sequential()\n",
    "model.add(Dense(units=8, input_dim=len(TENSED_POS_TAGS))) # layer\n",
    "model.add(Activation('relu')) # layer\n",
    "model.add(Dense(units=16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=3)) # layer\n",
    "model.add(Activation('softmax')) #layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.02, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy', 'mae']) # not layer\n",
    "\n",
    "print(TAG_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-10617950b433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_and_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_and_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(np_array(x_train), np_array(y_train), epochs=30, batch_size=32)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
